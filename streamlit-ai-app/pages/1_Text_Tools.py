import os
from datetime import datetime

import google.generativeai as genai
import pandas as pd
import streamlit as st


st.title("í…ìŠ¤íŠ¸ ë„êµ¬")
st.write("ìš”ì•½, ë²ˆì—­, ê¸€ì“°ê¸° í”¼ë“œë°±, í…ìŠ¤íŠ¸ ê¸¸ì´ ì‹œê°í™”ë¥¼ ì œê³µí•©ë‹ˆë‹¤.")

if not st.session_state.get("logged_in", False):
    st.error("ë¹„ë°€ë²ˆí˜¸ë¥¼ ë¨¼ì € ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤. í™ˆì—ì„œ ë¡œê·¸ì¸ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
    st.stop()

# ê¸°ë³¸ ì²« í•­ëª©(app)ì„ ìˆ¨ê¸°ê³  HOME ë§í¬ ì¶”ê°€
st.sidebar.page_link("app.py", label="HOME", icon="ğŸ ")
st.markdown(
    """
    <style>
        [data-testid="stSidebarNav"] ul li:nth-of-type(1) {
            display: none !important;
        }
    </style>
    """,
    unsafe_allow_html=True,
)

with st.expander("ë„ì›€ë§ ë³´ê¸°"):
    st.markdown(
        """
        1. ì•„ë˜ í…ìŠ¤íŠ¸ ìƒìì— ê¸´ ê¸€ì„ ë¶™ì—¬ ë„£ìœ¼ì„¸ìš”.  
        2. **ì‹¤í–‰** ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ì„ íƒí•œ ê¸°ëŠ¥ì´ ì‹¤í–‰ë©ë‹ˆë‹¤.  
        3. ê²°ê³¼ëŠ” ì•„ë˜ì— í‘œì‹œë©ë‹ˆë‹¤.  
        """
    )

HISTORY_PATH = "history.csv"

api_key = st.session_state.get("gemini_api_key") or st.session_state.get("api_key", "")
has_api_key = bool(api_key)
if not has_api_key:
    st.sidebar.warning("í™ˆì—ì„œ Gemini API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

AVAILABLE_MODELS = [
    "gemini-2.5-flash-lite",
    "gemini-2.5-flash",
]
selected_model = st.sidebar.selectbox("Gemini ëª¨ë¸ ì„ íƒ", AVAILABLE_MODELS, index=0)

tab_summary, tab_translate, tab_feedback, tab_length = st.tabs(
    ["í…ìŠ¤íŠ¸ ìš”ì•½", "ì˜ì–´ â†’ í•œêµ­ì–´ ë²ˆì—­", "ê¸€ì“°ê¸° í”¼ë“œë°±", "í…ìŠ¤íŠ¸ ê¸¸ì´ ì‹œê°í™”"]
)


def require_api_key():
    st.warning("í™ˆ í˜ì´ì§€ì—ì„œ Gemini API Keyë¥¼ ì…ë ¥í•œ ë’¤ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")


def log_history(action: str, input_text: str, output_text: str, model_name: str) -> None:
    """ìš”ì•½/ë²ˆì—­/í”¼ë“œë°± ê²°ê³¼ë¥¼ CSVë¡œ ëˆ„ì  ì €ì¥."""
    try:
        row = {
            "timestamp": datetime.utcnow().isoformat(),
            "action": action,
            "model": model_name,
            "input": input_text,
            "output": output_text,
        }
        df = pd.DataFrame([row])
        header_needed = not os.path.exists(HISTORY_PATH)
        df.to_csv(
            HISTORY_PATH,
            mode="a",
            header=header_needed,
            index=False,
            encoding="utf-8",
        )
    except Exception as exc:
        st.warning(f"history.csv ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {exc}")


def generate_with_fallback(prompt: str):
    """
    ì„ íƒ ëª¨ë¸ì´ ì‹¤íŒ¨í•  ê²½ìš° í˜¸í™˜ ëª¨ë¸ë¡œ ìˆœì°¨ ì‹œë„.
    ë°˜í™˜: (ì‘ë‹µ í…ìŠ¤íŠ¸, ì‚¬ìš© ëª¨ë¸ëª…) ë˜ëŠ” (None, None)
    """
    if not has_api_key:
        require_api_key()
        return None, None

    errors = []
    fallback_models = []
    for name in [selected_model, "gemini-2.5-flash-lite", "gemini-2.5-flash"]:
        if name not in fallback_models:
            fallback_models.append(name)

    for name in fallback_models:
        try:
            genai.configure(api_key=api_key)
            mdl = genai.GenerativeModel(name)
            resp = mdl.generate_content(prompt)
            st.caption(f"ì‚¬ìš© ëª¨ë¸: {name}")
            return resp.text, name
        except Exception as exc:
            errors.append(f"{name}: {exc}")
            continue

    st.error("ëª¨ë¸ í˜¸ì¶œì´ ëª¨ë‘ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ëª¨ë¸ì„ ì„ íƒí•˜ê±°ë‚˜ google-generativeai ë²„ì „ì„ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”.")
    for err in errors:
        st.error(err)
    return None, None


with tab_summary:
    summary_text = st.text_area(
        "", height=220, key="summary_text", placeholder="í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”."
    )
    if st.button("ì‹¤í–‰", key="summary_button"):
        if not summary_text.strip():
            st.warning("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            with st.spinner("ìš”ì•½ ì¤‘..."):
                prompt = (
                    "ë‹¤ìŒ ê¸€ì„ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì¤˜. "
                    "í•µì‹¬ë§Œ ë‚¨ê¸°ê³  ë¶ˆí•„ìš”í•œ ì˜ˆì‹œëŠ” ì œì™¸í•´.\n\n"
                    f"{summary_text}"
                )
                result, model_used = generate_with_fallback(prompt)
                if result:
                    st.success("ìš”ì•½ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.write(result)
                    log_history("summary", summary_text, result, model_used or "")

with tab_translate:
    translate_text = st.text_area(
        "", height=220, key="translate_text", placeholder="í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”."
    )
    if st.button("ì‹¤í–‰", key="translate_button"):
        if not translate_text.strip():
            st.warning("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            with st.spinner("ë²ˆì—­ ì¤‘..."):
                prompt = (
                    "Translate the following English text into Korean. "
                    "Return only the translated Korean text without explanations.\n\n"
                    f"{translate_text}"
                )
                result, model_used = generate_with_fallback(prompt)
                if result:
                    st.success("ë²ˆì—­ ê²°ê³¼")
                    st.write(result)
                    log_history("translate", translate_text, result, model_used or "")

with tab_feedback:
    feedback_text = st.text_area(
        "", height=220, key="feedback_text", placeholder="í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”."
    )
    if st.button("ì‹¤í–‰", key="feedback_button"):
        if not feedback_text.strip():
            st.warning("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            with st.spinner("í”¼ë“œë°± ì‘ì„± ì¤‘..."):
                prompt = (
                    "You are a writing coach. Provide concise, constructive Korean feedback on clarity, tone, and "
                    "structure of the following text. Include specific suggestions and an improved sample rewrite "
                    "no longer than 3 sentences.\n\n"
                    f"{feedback_text}"
                )
                result, model_used = generate_with_fallback(prompt)
                if result:
                    st.success("í”¼ë“œë°± ê²°ê³¼")
                    st.write(result)
                    log_history("feedback", feedback_text, result, model_used or "")

with tab_length:
    length_text = st.text_area(
        "", height=220, key="length_text", placeholder="í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”."
    )
    if st.button("ì‹¤í–‰", key="length_button"):
        if not length_text.strip():
            st.warning("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            char_count = len(length_text)
            word_count = len(length_text.split())
            data = pd.DataFrame(
                {"í•­ëª©": ["ë¬¸ì ìˆ˜", "ë‹¨ì–´ ìˆ˜"], "ê°’": [char_count, word_count]}
            ).set_index("í•­ëª©")
            st.bar_chart(data)
            st.write(f"ë¬¸ì ìˆ˜: {char_count}, ë‹¨ì–´ ìˆ˜: {word_count}")
